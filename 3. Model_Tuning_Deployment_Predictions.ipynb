{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4810e5",
   "metadata": {},
   "source": [
    "## The below script conducts hyperparameter tuning, model deployment, and inference predictions on the holdout test data for both a XGBoost and Linear-Learner model respectively.\n",
    "\n",
    "### Outline of Notebook:\n",
    "\n",
    "#### 3.1 Establish environment and define variables\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Function: <u>CSV_Reader()</u>\n",
    "#### 3.2 Perform K-Fold split and convert train datasets to protobuf format\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Function: <u>Export_Processed_Protobuf()</u>\n",
    "#### 3.3 Tune Hyperparameters\n",
    "#### 3.4 Build Models\n",
    "#### 3.5 Deploy Models\n",
    "#### 3.6 Make Batch Predictions on Test Data\n",
    "#### 3.7 Export test data with predictions\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Function: <u>Export_Processed_CSV()</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e3d89",
   "metadata": {},
   "source": [
    "### 3.1 Establish Environment and Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfa867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a7550",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df73a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ebc1041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "current_date = datetime.now()\n",
    "\n",
    "#Sagemaker/related Libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "s3 = boto3.client('s3')\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.session import Session\n",
    "\n",
    "#Machine Learning Libraries\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sklearn.model_selection import KFold\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import image_uris\n",
    "\n",
    "#Protobuf Libraries\n",
    "import io\n",
    "from io import StringIO\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d63f41",
   "metadata": {},
   "source": [
    "#### Here we define variables that will be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a7599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = 'diabetes-directory' #main directory\n",
    "input_prefix = 'diabetes_processed_data'  #sub-directory\n",
    "k_folder = 'k' #subdirectory for k-fold datasets\n",
    "\n",
    "test_dataset = 'reduced_dimensions_diabetes_test.csv' #holdout test set\n",
    "train_dataset = \"reduced_dimensions_diabetes_train.csv\" #set to be converted to protobuf and trained upon\n",
    "xgb_full_train_proto_filename = \"xgb_full_train_proto.data\" #final training dataset to train XGBoost model on optimized hyperparameters\n",
    "train_proto_filename = \"train_proto.data\" #final training dataset to train a Linear Learner model on optimized hyperparameters\n",
    "validation_proto_filename = \"validation_proto.data\" #final validation dataset to train a Linear Learner model on optimized hyperparameters\n",
    "test_with_predictions = \"test_with_predictions.csv\" #exporting our test dataset once all our predictions have been made\n",
    "\n",
    "feature_dim = 61 #The number of features we will use to train our linear learner model\n",
    "linear_job_name = \"diabetes-job-linear\" #job name for the linear learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e5522",
   "metadata": {},
   "source": [
    "#### Defining filepaths that we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f87c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_proto_filepath = 's3://{}/{}/{}/{}'.format(bucket, input_prefix, k_folder, train_proto_filename)\n",
    "hyperparam_output_filepath = \"s3://{}/{}/hyperparam_output\".format(bucket, input_prefix)\n",
    "XGB_model_output_filepath = \"s3://{}/{}/xgb_output\".format(bucket, input_prefix)\n",
    "Linear_model_output_filepath = \"s3://{}/{}/linear_output\".format(bucket, input_prefix)\n",
    "linear_training_data_location = 's3://{}/{}/{}/{}'.format(bucket, input_prefix, k_folder, train_proto_filename)\n",
    "linear_validation_data_location = 's3://{}/{}/{}/{}'.format(bucket, input_prefix, k_folder, validation_proto_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93ba90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_Reader(bucket, subfolder, source_file_name):\n",
    "    \n",
    "    '''The CSV_Reader() function takes in the names of the bucket, subfolder, and source file name, and desired dataframe name. \n",
    "    It first constructs the filepath, and then imports the file residing at this filepath, based on the title fed to the function.\n",
    "    \n",
    "    Arguments \n",
    "    --------- \n",
    "    bucket: Head S3 repository bucket\n",
    "    subfolder: Subfolder containing the source data\n",
    "    source_file_name: Name of source CSV data file \n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    Returns the source data in a pandas dataframe '''\n",
    "    \n",
    "    data_location = 's3://{}/{}/{}'.format(bucket, subfolder, source_file_name)  \n",
    "    dataset = pd.read_csv(data_location, low_memory=False, header='infer')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055298a",
   "metadata": {},
   "source": [
    "#### Reading in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50bbc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = CSV_Reader(bucket, input_prefix, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f00431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85096, 62)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>discharge_disposition_hospice</th>\n",
       "      <th>diag_2_blooddis</th>\n",
       "      <th>diag_1_mentaldis</th>\n",
       "      <th>diag_2_infection</th>\n",
       "      <th>diag_1_skin</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>diag_3_neoplasm</th>\n",
       "      <th>age_3</th>\n",
       "      <th>max_glu_serum_&gt;300</th>\n",
       "      <th>max_glu_serum_&gt;200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79364</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       readmitted  num_lab_procedures  num_medications  time_in_hospital  \\\n",
       "79364           0                  49               28                 3   \n",
       "\n",
       "       number_inpatient  num_procedures  number_diagnoses  number_outpatient  \\\n",
       "79364                 0               3                 9                  0   \n",
       "\n",
       "       number_emergency  gender_Male  ...  discharge_disposition_hospice  \\\n",
       "79364                 0            1  ...                              0   \n",
       "\n",
       "       diag_2_blooddis  diag_1_mentaldis  diag_2_infection  diag_1_skin  \\\n",
       "79364                0                 0                 0            0   \n",
       "\n",
       "       race_Hispanic  diag_3_neoplasm  age_3  max_glu_serum_>300  \\\n",
       "79364              0                0      0                   0   \n",
       "\n",
       "       max_glu_serum_>200  \n",
       "79364                   0  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(diabetes.shape)\n",
    "diabetes.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e671ad2",
   "metadata": {},
   "source": [
    "### 3.2 Perform K-Fold split and convert train datasets to protobuf format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd50e7f",
   "metadata": {},
   "source": [
    "Here we take the data-preparation-steps required to train our models and optimize our hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1367c",
   "metadata": {},
   "source": [
    "#### Preparing a function that will convert a dataset into protobuf format and export to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efdd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Export_Processed_Protobuf(bucket, processed_data_folder, k_folder, local_file, S3_file_name):\n",
    "    \n",
    "    '''Exports a dataframe in protobuf format, and sends it to a specified S3 bucket location\n",
    "    \n",
    "    Arguments \n",
    "    --------- \n",
    "    bucket: A list of the columns (i.e. the 3 diagnosis columns) to be updated\n",
    "    processed_data_folder: the relevant subfolder within the main bucket\n",
    "    local_file_name: The name of the dataframe within the notebook\n",
    "    S3_file_name: The name of the file upon export (with .data extension included)\n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    Exports a protobuf file to a specified S3 location'''\n",
    "    \n",
    "#Here we seperate out the input and output values\n",
    "    X_values = local_file.drop(columns='readmitted').values\n",
    "    y_values = local_file['readmitted'].values\n",
    "    \n",
    "#Here we set up our code to transform the data    \n",
    "    f = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(f, X_values.astype('float32'), y_values.astype('float32'))\n",
    "    f.seek(0)\n",
    "    \n",
    "#Here we upload the data    \n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object('{}/{}/{}'.format(processed_data_folder, k_folder, S3_file_name)).upload_fileobj(f)\n",
    "    training_recordIO_protobuf_location = 's3://{}/{}/{}/{}'.format(bucket, processed_data_folder, k_folder, S3_file_name)\n",
    "    \n",
    "    print('The Pipe mode recordIO protobuf training data: {}'.format(training_recordIO_protobuf_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb35c0",
   "metadata": {},
   "source": [
    "Protobuf data format provides a more computationally-effecient means of processing data for our multiple training jobs (relative to .csv format). \n",
    "\n",
    "Therefore, it is good operational practice to convert our finalized training data into protobuf format, as it will be computed upon extensively during the training process. Once a finalized model has been trained off of this data, our holdout test dataset (still in csv format) can be run through the model, providing easily interpretable inference on our final test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad4436",
   "metadata": {},
   "source": [
    "#### Exporting the full train dataset to S3 in protobuf. This will be later used to train our final XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e15024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/xgb_full_train_proto.data\n"
     ]
    }
   ],
   "source": [
    "Export_Processed_Protobuf(bucket, input_prefix, k_folder, diabetes, xgb_full_train_proto_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa53ce13",
   "metadata": {},
   "source": [
    "#### Here, we create an 80/20 split on our training data for our final Linear Learner model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e1741",
   "metadata": {},
   "source": [
    "While our final XGBoost model can be trained off of a single comprehensive train dataset, our final Linear Learner model requires a seperate training and validation dataset (separate from our K-fold datasets) for its training. We provide this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03120cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(diabetes)\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random indices for the train and test sets\n",
    "indices = np.random.permutation(total_rows)\n",
    "train_size = int(0.8 * total_rows)\n",
    "\n",
    "# Use the first 80% of indices for training, the rest for testing\n",
    "train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "# Create training and test sets using the selected indices\n",
    "optimized_linear_train_set = diabetes.iloc[train_indices]  # For pandas DataFrame\n",
    "optimized_linear_test_set = diabetes.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fea1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68076, 62)\n",
      "(17020, 62)\n"
     ]
    }
   ],
   "source": [
    "print(optimized_linear_train_set.shape)\n",
    "print(optimized_linear_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95430e2d",
   "metadata": {},
   "source": [
    "#### Here we export our final Linear Learner Train/Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b956e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/train_proto.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/validation_proto.data\n"
     ]
    }
   ],
   "source": [
    "Export_Processed_Protobuf(bucket, input_prefix, k_folder, optimized_linear_train_set, train_proto_filename)\n",
    "Export_Processed_Protobuf(bucket, input_prefix, k_folder, optimized_linear_test_set, validation_proto_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a4018",
   "metadata": {},
   "source": [
    "#### Here we specify indicies for our different 5-K-Folds. These 5 folds will create 5 distinct permeations of train/validation datasets for our model to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3d273ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the number of folds for k-fold cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Use globals() to create variables dynamically\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(diabetes), 1):\n",
    "    # Creates variables for train and valid datasets dynamically\n",
    "    globals()[f'train_data_{fold}'] = diabetes.iloc[train_index].copy()\n",
    "    globals()[f'validation_data_{fold}'] = diabetes.iloc[valid_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51110b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>discharge_disposition_hospice</th>\n",
       "      <th>diag_2_blooddis</th>\n",
       "      <th>diag_1_mentaldis</th>\n",
       "      <th>diag_2_infection</th>\n",
       "      <th>diag_1_skin</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>diag_3_neoplasm</th>\n",
       "      <th>age_3</th>\n",
       "      <th>max_glu_serum_&gt;300</th>\n",
       "      <th>max_glu_serum_&gt;200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      readmitted  num_lab_procedures  num_medications  time_in_hospital  \\\n",
       "1917           0                  25               12                 3   \n",
       "\n",
       "      number_inpatient  num_procedures  number_diagnoses  number_outpatient  \\\n",
       "1917                 0               3                 6                  2   \n",
       "\n",
       "      number_emergency  gender_Male  ...  discharge_disposition_hospice  \\\n",
       "1917                 0            0  ...                              0   \n",
       "\n",
       "      diag_2_blooddis  diag_1_mentaldis  diag_2_infection  diag_1_skin  \\\n",
       "1917                0                 0                 0            0   \n",
       "\n",
       "      race_Hispanic  diag_3_neoplasm  age_3  max_glu_serum_>300  \\\n",
       "1917              1                0      0                   0   \n",
       "\n",
       "      max_glu_serum_>200  \n",
       "1917                   0  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d067b",
   "metadata": {},
   "source": [
    "#### The below code uses our code indecies to export our 10 different datasets to be used in our hyperparameter tuning (5 training and 5 validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8410226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/train_data_1.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/validation_data_1.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/train_data_2.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/validation_data_2.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/train_data_3.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/validation_data_3.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/train_data_4.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/validation_data_4.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/train_data_5.data\n",
      "The Pipe mode recordIO protobuf training data: s3://diabetes-directory/diabetes_processed_data/k/validation_data_5.data\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    train_dataset_name = f'train_data_{i}'\n",
    "    train_dataset = globals()[train_dataset_name]\n",
    "    train_proto_filename = f'{train_dataset_name}.data'\n",
    "    Export_Processed_Protobuf(bucket, input_prefix, k_folder, train_dataset, train_proto_filename)\n",
    "    \n",
    "    validation_dataset_name = f'validation_data_{i}'\n",
    "    validation_dataset = globals()[validation_dataset_name]\n",
    "    validation_csv_filename = f'{validation_dataset_name}.data'\n",
    "    Export_Processed_Protobuf(bucket, input_prefix, k_folder, validation_dataset, validation_csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659c174",
   "metadata": {},
   "source": [
    "#### The below code makes a list of the different train/validation filepath pairings to be referenced in our hyperparameter tuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebd3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('s3://diabetes-directory/diabetes_processed_data/k/train_data_1.data', 's3://diabetes-directory/diabetes_processed_data/k/validation_data_1.data'), ('s3://diabetes-directory/diabetes_processed_data/k/train_data_2.data', 's3://diabetes-directory/diabetes_processed_data/k/validation_data_2.data'), ('s3://diabetes-directory/diabetes_processed_data/k/train_data_3.data', 's3://diabetes-directory/diabetes_processed_data/k/validation_data_3.data'), ('s3://diabetes-directory/diabetes_processed_data/k/train_data_4.data', 's3://diabetes-directory/diabetes_processed_data/k/validation_data_4.data'), ('s3://diabetes-directory/diabetes_processed_data/k/train_data_5.data', 's3://diabetes-directory/diabetes_processed_data/k/validation_data_5.data')]\n"
     ]
    }
   ],
   "source": [
    "train_filepath = []\n",
    "validation_filepath = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    train_filepath.append(f's3://{bucket}/{input_prefix}/{k_folder}/train_data_{i}.data')\n",
    "    validation_filepath.append(f's3://{bucket}/{input_prefix}/{k_folder}/validation_data_{i}.data')\n",
    "\n",
    "filepaths_list = list(zip(train_filepath, validation_filepath))\n",
    "print(filepaths_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a4c3a",
   "metadata": {},
   "source": [
    "## 3.3 Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8baed7c",
   "metadata": {},
   "source": [
    "Here we determine the optimal hyperparameters for both our XGBoost and Linear Learner models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83cafd",
   "metadata": {},
   "source": [
    "### 3.3.1 XGBoost Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9fc90",
   "metadata": {},
   "source": [
    "#### Below we configure a range of hyperparameters, and related variables, for use in our  XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aed7d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"1\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"eta\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"2\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"alpha\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"min_child_weight\"\n",
    "        },\n",
    "\n",
    "      ],\n",
    "      \"IntegerParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"max_depth\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "      \"MaxNumberOfTrainingJobs\": 50,\n",
    "      \"MaxParallelTrainingJobs\": 5\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "      \"MetricName\": \"validation:auc\",\n",
    "      \"Type\": \"Maximize\"\n",
    "    },\n",
    "    \"RandomSeed\" : 123\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258a537",
   "metadata": {},
   "source": [
    "#### Here we define the 5 sequential hyperparameter tuning jobs which we will run on our XGBoost model, with our 5 K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdc5afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_tuning_job_names = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    # sagemaker.image_uris.retrieve\n",
    "    training_image = sagemaker.image_uris.retrieve(framework='xgboost', region='us-east-1', version='1.0-1')\n",
    "\n",
    "    # Identifying the optimal hyperparameters, and specifying input/output file paths\n",
    "    XGB_training_job_definition = {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            \"TrainingImage\": training_image,\n",
    "            \"TrainingInputMode\": \"Pipe\"\n",
    "        },\n",
    "        \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"ContentType\": \"application/x-recordio-protobuf\",  # Change content type to protobuf\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": filepaths_list[i][0]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"ChannelName\": \"validation\",\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"ContentType\": \"application/x-recordio-protobuf\",  # Change content type to protobuf\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": filepaths_list[i][1]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": hyperparam_output_filepath\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.c4.2xlarge\",\n",
    "            \"VolumeSizeInGB\": 10\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"StaticHyperParameters\": {\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"num_round\": \"100\",\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"rate_drop\": \"0.3\",\n",
    "            \"tweedie_variance_power\": \"1.4\"\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 43200\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Tuning and training\n",
    "    XGB_tuning_job_name = f'dia-extrgboo-{i+1}'\n",
    "    XGB_tuning_job_names.append(XGB_tuning_job_name)\n",
    "\n",
    "    smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName=XGB_tuning_job_name,\n",
    "                                               HyperParameterTuningJobConfig=XGB_tuning_job_config,\n",
    "                                               TrainingJobDefinition=XGB_training_job_definition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb20ef",
   "metadata": {},
   "source": [
    "<b>Important</b> It should be noted that the above cell takes a few minutes to run, as it launches multiple hyperparameter tuning jobs. If running this script in your own environment, please wait for these to finish before continuing to run the remainder of the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba9871",
   "metadata": {},
   "source": [
    "#### Here we will go through the results from our training jobs, and select those with the best ROC AUC score. These jobs, and their corresponding hyperparameters, will be recorded and applied to our final trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d33efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_best_job_names = []\n",
    "XGB_best_job_hyperparameters = []\n",
    "XGB_auc_scores = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    tuner = sagemaker.HyperparameterTuningJobAnalytics(XGB_tuning_job_names[i])\n",
    "    XGB_best_training_job = tuner.dataframe().sort_values('FinalObjectiveValue', ascending=False).iloc[0]\n",
    "    XGB_best_training_job_name = XGB_best_training_job['TrainingJobName']\n",
    "\n",
    "    XGB_response = smclient.describe_training_job(TrainingJobName=XGB_best_training_job_name)\n",
    "    XGB_best_hyperparameters = XGB_response['HyperParameters']\n",
    "    \n",
    "    # Append values to the lists\n",
    "    XGB_best_job_names.append(XGB_best_training_job_name)\n",
    "    XGB_best_job_hyperparameters.append(XGB_best_hyperparameters)\n",
    "\n",
    "    # Extract AUC from training job metrics\n",
    "    XGB_training_job_metrics = smclient.describe_training_job(TrainingJobName=XGB_best_training_job_name)['FinalMetricDataList']\n",
    "    for metric in XGB_training_job_metrics:\n",
    "        if metric['MetricName'] == 'validation:auc':\n",
    "            auc_value = metric['Value']\n",
    "            break\n",
    "    \n",
    "    XGB_auc_scores.append(auc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713834f8",
   "metadata": {},
   "source": [
    "Aggregating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fc49dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_top_jobs = pd.DataFrame(list(zip(XGB_best_job_names, XGB_auc_scores)), columns = ['job_name', 'auc_scores']).sort_values(by='auc_scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb153e",
   "metadata": {},
   "source": [
    "Assessing best individual jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3114c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_name</th>\n",
       "      <th>auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dia-extrgboo-5-040-84b04cad</td>\n",
       "      <td>0.67265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dia-extrgboo-1-026-6d4cf70d</td>\n",
       "      <td>0.66995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia-extrgboo-2-027-010f3947</td>\n",
       "      <td>0.66844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dia-extrgboo-4-020-96151d6b</td>\n",
       "      <td>0.66478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dia-extrgboo-3-039-bb7f03f3</td>\n",
       "      <td>0.65979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      job_name  auc_scores\n",
       "4  dia-extrgboo-5-040-84b04cad     0.67265\n",
       "0  dia-extrgboo-1-026-6d4cf70d     0.66995\n",
       "1  dia-extrgboo-2-027-010f3947     0.66844\n",
       "3  dia-extrgboo-4-020-96151d6b     0.66478\n",
       "2  dia-extrgboo-3-039-bb7f03f3     0.65979"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_top_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27f6dcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dia-extrgboo-5-040-84b04cad'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_top_jobs.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2c483",
   "metadata": {},
   "source": [
    "#### Identifying the best hyperparameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "871c5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_response = smclient.describe_training_job(TrainingJobName=XGB_top_jobs.iloc[0,0])\n",
    "XGB_best_hyperparameters = XGB_response['HyperParameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82f896",
   "metadata": {},
   "source": [
    "Identifying the best set of hyperparameters- which we will feed into our optimized model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2f6f2",
   "metadata": {},
   "source": [
    "### 3.3.2 Linear Learner Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a7b91",
   "metadata": {},
   "source": [
    "#### Below we configure a range of hyperparameters, and related variables, for use in our Linear Learner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ffac15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "        \"CategoricalParameterRanges\": [\n",
    "            {\n",
    "                \"Name\": \"use_bias\",\n",
    "                \"Values\": [\"true\", \"false\"]\n",
    "            }\n",
    "        ],\n",
    "        \"ContinuousParameterRanges\": [\n",
    "            {\n",
    "                \"Name\": \"l1\",\n",
    "                \"MaxValue\": \"1.0\",\n",
    "                \"MinValue\": \"0.0001\",\n",
    "                \"ScalingType\": \"Logarithmic\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"learning_rate\",\n",
    "                \"MaxValue\": \"1.0\",\n",
    "                \"MinValue\": \"0.0001\",\n",
    "                \"ScalingType\": \"Logarithmic\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"wd\",\n",
    "                \"MaxValue\": \"1.0\",\n",
    "                \"MinValue\": \"0.0001\",\n",
    "                \"ScalingType\": \"Logarithmic\"\n",
    "            }\n",
    "        ],\n",
    "        \"IntegerParameterRanges\": [\n",
    "            {\n",
    "                \"Name\": \"mini_batch_size\",\n",
    "                \"MaxValue\": \"5000\",\n",
    "                \"MinValue\": \"500\",\n",
    "                \"ScalingType\": \"Linear\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "        \"MaxNumberOfTrainingJobs\": 50,\n",
    "        \"MaxParallelTrainingJobs\": 5\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "        \"MetricName\": \"validation:roc_auc_score\",\n",
    "        \"Type\": \"Maximize\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa2913",
   "metadata": {},
   "source": [
    "#### Here we define the 5 sequential hyperparameter tuning jobs which we will run on our Linear Learner model, with our 5 K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca3a47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify SageMaker estimator\n",
    "linear_learner_image = sagemaker.image_uris.retrieve(\"linear-learner\", region='us-east-1', version='1')\n",
    "\n",
    "LL_tuning_job_names = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    # Identifying the optimal hyperparameters\n",
    "    LL_training_job_definition = {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            \"TrainingImage\": linear_learner_image,\n",
    "            \"TrainingInputMode\": \"Pipe\",\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": filepaths_list[i][0],\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    }\n",
    "                },\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"ContentType\": \"application/x-recordio-protobuf\",  # Set content type to protobuf\n",
    "            },\n",
    "            {\n",
    "                \"ChannelName\": \"validation\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": filepaths_list[i][1],\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    }\n",
    "                },\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"ContentType\": \"application/x-recordio-protobuf\",  # Set content type to protobuf\n",
    "            },\n",
    "        ],\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": hyperparam_output_filepath,\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.c4.2xlarge\",\n",
    "            \"VolumeSizeInGB\": 10,\n",
    "        },\n",
    "        \"StaticHyperParameters\": {\n",
    "            \"predictor_type\": \"binary_classifier\",\n",
    "            \"feature_dim\": str(feature_dim),\n",
    "            #\"mini_batch_size\": \"500\",\n",
    "            \"epochs\": \"15\",\n",
    "            \"loss\": \"auto\",\n",
    "            \"normalize_data\": \"true\",\n",
    "            \"normalize_label\": \"auto\",\n",
    "            #\"wd\": \"auto\",\n",
    "            \"optimizer\": \"auto\",\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 43200,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Tuning and training\n",
    "    LL_tuning_job_name = f'dll-{i+1}-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "    LL_tuning_job_names.append(LL_tuning_job_name)\n",
    "\n",
    "    smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName=LL_tuning_job_name,\n",
    "                                               HyperParameterTuningJobConfig=LL_tuning_job_config,\n",
    "                                               TrainingJobDefinition=LL_training_job_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad3257c",
   "metadata": {},
   "source": [
    "<b>Important</b> It should be noted that the above cell takes a few minutes to run, as it launches multiple hyperparameter tuning jobs. If running this script in your own environment, please wait for these to finish before continuing to run the remainder of the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74ee65",
   "metadata": {},
   "source": [
    "#### Here we will go through the results from our training jobs, and select those with the best ROC AUC score. These jobs, and their corresponding hyperparameters, will be recorded and applied to our final trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "646b60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_best_job_names = []\n",
    "LL_best_job_hyperparameters = []\n",
    "LL_auc_scores = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    tuner = sagemaker.HyperparameterTuningJobAnalytics(LL_tuning_job_names[i])\n",
    "    LL_best_training_job = tuner.dataframe().sort_values('FinalObjectiveValue', ascending=False).iloc[0]\n",
    "    LL_best_training_job_name = LL_best_training_job['TrainingJobName']\n",
    "\n",
    "    LL_response = smclient.describe_training_job(TrainingJobName=LL_best_training_job_name)\n",
    "    LL_best_hyperparameters = LL_response['HyperParameters']\n",
    "    \n",
    "    # Append values to the lists\n",
    "    LL_best_job_names.append(LL_best_training_job_name)\n",
    "    LL_best_job_hyperparameters.append(LL_best_hyperparameters)\n",
    "\n",
    "    # Extract AUC from training job metrics\n",
    "    LL_training_job_metrics = smclient.describe_training_job(TrainingJobName=LL_best_training_job_name)['FinalMetricDataList']\n",
    "    for metric in LL_training_job_metrics:\n",
    "        if metric['MetricName'] == 'validation:roc_auc_score':\n",
    "            auc_value = metric['Value']\n",
    "            break\n",
    "    \n",
    "    LL_auc_scores.append(auc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4807ca2",
   "metadata": {},
   "source": [
    "Aggregating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61fee325",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_top_jobs = pd.DataFrame(list(zip(LL_best_job_names, LL_auc_scores)), columns = ['job_name', 'auc_scores']).sort_values(by='auc_scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291cbbf",
   "metadata": {},
   "source": [
    "Assessing best individual jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00b95bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_name</th>\n",
       "      <th>auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dll-5-20231222172130-050-885d7370</td>\n",
       "      <td>0.662167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dll-4-20231222172130-044-cd31ef2f</td>\n",
       "      <td>0.660985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dll-1-20231222172125-021-403fa0cc</td>\n",
       "      <td>0.659790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dll-2-20231222172126-037-def96f72</td>\n",
       "      <td>0.654809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dll-3-20231222172128-050-8fb1c734</td>\n",
       "      <td>0.652701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            job_name  auc_scores\n",
       "4  dll-5-20231222172130-050-885d7370    0.662167\n",
       "3  dll-4-20231222172130-044-cd31ef2f    0.660985\n",
       "0  dll-1-20231222172125-021-403fa0cc    0.659790\n",
       "1  dll-2-20231222172126-037-def96f72    0.654809\n",
       "2  dll-3-20231222172128-050-8fb1c734    0.652701"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL_top_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20148b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dll-5-20231222172130-050-885d7370'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL_top_jobs.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4329bb",
   "metadata": {},
   "source": [
    "#### Identifying the best hyperparameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "904d2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_response = smclient.describe_training_job(TrainingJobName=LL_top_jobs.iloc[0,0])\n",
    "LL_best_hyperparameters = LL_response['HyperParameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb29aa5",
   "metadata": {},
   "source": [
    "Identifying the best set of hyperparameters- which we will feed into our optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dc144d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': 'validation:roc_auc_score',\n",
       " 'epochs': '15',\n",
       " 'feature_dim': '61',\n",
       " 'l1': '1.0',\n",
       " 'learning_rate': '0.0029353939183486017',\n",
       " 'loss': 'auto',\n",
       " 'mini_batch_size': '500',\n",
       " 'normalize_data': 'true',\n",
       " 'normalize_label': 'auto',\n",
       " 'optimizer': 'auto',\n",
       " 'predictor_type': 'binary_classifier',\n",
       " 'use_bias': 'true',\n",
       " 'wd': '0.00010000000000000009'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL_best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a0644",
   "metadata": {},
   "source": [
    "### 3.4 Training Optimized Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526513ec",
   "metadata": {},
   "source": [
    "#### In the below cell, we now train an XGBoost model with the hyperparameters specified in the above training job(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f178c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-12-22-18-02-40-470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-22 18:02:40 Starting - Starting the training job...\n",
      "2023-12-22 18:02:56 Starting - Preparing the instances for training.........\n",
      "2023-12-22 18:04:20 Downloading - Downloading input data...\n",
      "2023-12-22 18:04:50 Downloading - Downloading the training image......\n",
      "2023-12-22 18:05:45 Training - Training image download completed. Training in progress..\u001b[34m[2023-12-22 18:06:02.338 ip-10-2-67-26.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:02.361 ip-10-2-67-26.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] File path /opt/ml/input/data/train of input files\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Making smlinks from folder /opt/ml/input/data/train to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] creating symlink between Path /opt/ml/input/data/train/train_proto.data and destination /tmp/sagemaker_xgboost_input_data/train_proto.data1879135274972825121\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Setting up HPO optimized metric to be : auc\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Train matrix has 68076 rows and 61 columns\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:02.905 ip-10-2-67-26.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:02.906 ip-10-2-67-26.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:02.907 ip-10-2-67-26.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:02.907 ip-10-2-67-26.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-12-22:18:06:02:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[18:06:02] WARNING: ../src/learner.cc:767: \u001b[0m\n",
      "\u001b[34mParameters: { \"rate_drop\", \"tweedie_variance_power\" } are not used.\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.63337\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:03.018 ip-10-2-67-26.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2023-12-22 18:06:03.021 ip-10-2-67-26.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.63414\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.63418\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.63434\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.63465\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.64186\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.64196\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.64930\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.64998\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.65133\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.65182\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.65297\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.65482\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.65642\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.65771\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.65888\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.66018\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.66179\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.66268\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.66359\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.66555\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.66658\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.66726\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.66854\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.66962\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.67077\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.67129\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.67198\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.67323\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.67433\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.67483\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.67557\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.67698\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.67750\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.67801\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.67879\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.67922\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.67973\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.68054\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.68125\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.68183\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.68210\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.68302\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.68354\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.68407\u001b[0m\n",
      "\u001b[34m[45]#011train-auc:0.68475\u001b[0m\n",
      "\u001b[34m[46]#011train-auc:0.68527\u001b[0m\n",
      "\u001b[34m[47]#011train-auc:0.68570\u001b[0m\n",
      "\u001b[34m[48]#011train-auc:0.68642\u001b[0m\n",
      "\u001b[34m[49]#011train-auc:0.68691\u001b[0m\n",
      "\u001b[34m[50]#011train-auc:0.68753\u001b[0m\n",
      "\u001b[34m[51]#011train-auc:0.68792\u001b[0m\n",
      "\u001b[34m[52]#011train-auc:0.68830\u001b[0m\n",
      "\u001b[34m[53]#011train-auc:0.68886\u001b[0m\n",
      "\u001b[34m[54]#011train-auc:0.68937\u001b[0m\n",
      "\u001b[34m[55]#011train-auc:0.68957\u001b[0m\n",
      "\u001b[34m[56]#011train-auc:0.69016\u001b[0m\n",
      "\u001b[34m[57]#011train-auc:0.69056\u001b[0m\n",
      "\u001b[34m[58]#011train-auc:0.69086\u001b[0m\n",
      "\u001b[34m[59]#011train-auc:0.69116\u001b[0m\n",
      "\u001b[34m[60]#011train-auc:0.69162\u001b[0m\n",
      "\u001b[34m[61]#011train-auc:0.69185\u001b[0m\n",
      "\u001b[34m[62]#011train-auc:0.69231\u001b[0m\n",
      "\u001b[34m[63]#011train-auc:0.69278\u001b[0m\n",
      "\u001b[34m[64]#011train-auc:0.69336\u001b[0m\n",
      "\u001b[34m[65]#011train-auc:0.69363\u001b[0m\n",
      "\u001b[34m[66]#011train-auc:0.69403\u001b[0m\n",
      "\u001b[34m[67]#011train-auc:0.69426\u001b[0m\n",
      "\u001b[34m[68]#011train-auc:0.69472\u001b[0m\n",
      "\u001b[34m[69]#011train-auc:0.69519\u001b[0m\n",
      "\u001b[34m[70]#011train-auc:0.69565\u001b[0m\n",
      "\u001b[34m[71]#011train-auc:0.69621\u001b[0m\n",
      "\u001b[34m[72]#011train-auc:0.69670\u001b[0m\n",
      "\u001b[34m[73]#011train-auc:0.69712\u001b[0m\n",
      "\u001b[34m[74]#011train-auc:0.69755\u001b[0m\n",
      "\u001b[34m[75]#011train-auc:0.69791\u001b[0m\n",
      "\u001b[34m[76]#011train-auc:0.69807\u001b[0m\n",
      "\u001b[34m[77]#011train-auc:0.69848\u001b[0m\n",
      "\u001b[34m[78]#011train-auc:0.69885\u001b[0m\n",
      "\u001b[34m[79]#011train-auc:0.69911\u001b[0m\n",
      "\u001b[34m[80]#011train-auc:0.69943\u001b[0m\n",
      "\u001b[34m[81]#011train-auc:0.69988\u001b[0m\n",
      "\u001b[34m[82]#011train-auc:0.69994\u001b[0m\n",
      "\u001b[34m[83]#011train-auc:0.70026\u001b[0m\n",
      "\u001b[34m[84]#011train-auc:0.70056\u001b[0m\n",
      "\u001b[34m[85]#011train-auc:0.70092\u001b[0m\n",
      "\u001b[34m[86]#011train-auc:0.70122\u001b[0m\n",
      "\u001b[34m[87]#011train-auc:0.70163\u001b[0m\n",
      "\u001b[34m[88]#011train-auc:0.70208\u001b[0m\n",
      "\u001b[34m[89]#011train-auc:0.70260\u001b[0m\n",
      "\u001b[34m[90]#011train-auc:0.70301\u001b[0m\n",
      "\u001b[34m[91]#011train-auc:0.70330\u001b[0m\n",
      "\u001b[34m[92]#011train-auc:0.70359\u001b[0m\n",
      "\u001b[34m[93]#011train-auc:0.70397\u001b[0m\n",
      "\u001b[34m[94]#011train-auc:0.70451\u001b[0m\n",
      "\u001b[34m[95]#011train-auc:0.70461\u001b[0m\n",
      "\u001b[34m[96]#011train-auc:0.70491\u001b[0m\n",
      "\u001b[34m[97]#011train-auc:0.70522\u001b[0m\n",
      "\u001b[34m[98]#011train-auc:0.70530\u001b[0m\n",
      "\u001b[34m[99]#011train-auc:0.70559\u001b[0m\n",
      "\n",
      "2023-12-22 18:06:27 Uploading - Uploading generated training model\n",
      "2023-12-22 18:06:27 Completed - Training job completed\n",
      "Training seconds: 128\n",
      "Billable seconds: 128\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", 'us-east-1', \"1.7-1\")\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          #The optimal hyperparameters from tuning are brought into our new model\n",
    "                                          hyperparameters=XGB_best_hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=XGB_model_output_filepath)\n",
    "\n",
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"application/x-recordio-protobuf\"\n",
    "train_input = TrainingInput(s3_train_proto_filepath, content_type=content_type)\n",
    "#validation_input = TrainingInput(s3_test_filepath, content_type=content_type)\n",
    "\n",
    "# execute the XGBoost training job\n",
    "xgb_estimator.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e787d6b",
   "metadata": {},
   "source": [
    ".706 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcdb44",
   "metadata": {},
   "source": [
    "#### In the below cell, we now train an Linear Learner model with the hyperparameters specified in the above training job(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: diabetes-job-linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-22 18:06:53 Starting - Starting the training job...\n",
      "2023-12-22 18:07:09 Starting - Preparing the instances for training.........\n",
      "2023-12-22 18:08:37 Downloading - Downloading input data...\n",
      "2023-12-22 18:09:22 Downloading - Downloading the training image........"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear_container = image_uris.retrieve('linear-learner', boto3.Session().region_name, '1')\n",
    "\n",
    "# Setup the LinearLeaner algorithm from the ECR container\n",
    "linear_estimator = sagemaker.estimator.Estimator(linear_container,\n",
    "                                       role,\n",
    "                                       hyperparameters=LL_best_hyperparameters,\n",
    "                                       instance_count=1, \n",
    "                                       instance_type='ml.c4.xlarge',\n",
    "                                       output_path=Linear_model_output_filepath,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       input_mode='Pipe')\n",
    "\n",
    "\n",
    "# Launch a training job. This method calls the CreateTrainingJob API call\n",
    "data_channels = {\n",
    "    'train': linear_training_data_location,\n",
    "    'validation': linear_validation_data_location\n",
    "}\n",
    "linear_estimator.fit(data_channels, job_name=linear_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d535b",
   "metadata": {},
   "source": [
    "The optimal AUC 0.6590648260645642"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3d746",
   "metadata": {},
   "source": [
    "### 3.5 Deploy Optimized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8efc1",
   "metadata": {},
   "source": [
    "#### Below we deploy our models for inference. The type and instance count of underlying cumpute resources are specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_deployed_predictor = xgb_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd27e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    }
   ],
   "source": [
    "linear_deployed_predictor = linear_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e701785",
   "metadata": {},
   "source": [
    "### 3.6 Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e89121",
   "metadata": {},
   "source": [
    "#### Now that our models are deployed, we can run our previously unseen test dataset through the model and record the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461ac5b",
   "metadata": {},
   "source": [
    " We can then ammend these predictions back to the test dataset as additional columns, and conduct statistical/operational assessments on each model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123457ff",
   "metadata": {},
   "source": [
    "#### Reading in the holdout test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bf5d97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes_test = CSV_Reader(bucket, input_prefix, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb930edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 62)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4771ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['readmitted', 'num_lab_procedures', 'num_medications',\n",
       "       'time_in_hospital', 'number_inpatient', 'num_procedures',\n",
       "       'number_diagnoses', 'number_outpatient', 'number_emergency',\n",
       "       'gender_Male', 'admission_source_id_1', 'change', 'diag_3_Nothing',\n",
       "       'age_9', 'diag_2_Nothing', 'medication_insulin', 'diag_2_respiratory',\n",
       "       'admission_type_id_3', 'diag_2_urogenital', 'age_6',\n",
       "       'medication_glyburide', 'diag_3_respiratory', 'diag_3_metabolic',\n",
       "       'medication_metformin', 'discharge_disposition_hhealth',\n",
       "       'diag_1_digestive', 'diag_1_respiratory', 'diag_1_injury', 'age_5',\n",
       "       'discharge_disposition_outpatient', 'diag_3_urogenital',\n",
       "       'discharge_disposition_nursing', 'diag_3_injury', 'diag_1_Nothing',\n",
       "       'any_medication', 'diag_1_urogenital', 'A1Cresult_Norm',\n",
       "       'diag_3_digestive', 'discharge_disposition_unknown', 'A1Cresult_>7',\n",
       "       'diag_2_skin', 'admission_source_id_8', 'diag_3_other',\n",
       "       'discharge_disposition_hospital', 'race_Other', 'diag_1_other',\n",
       "       'diag_3_skin', 'diag_1_infection', 'diag_1_musculoskeletal',\n",
       "       'diag_2_neoplasm', 'diag_1_neoplasm', 'admission_source_id_4',\n",
       "       'discharge_disposition_hospice', 'diag_2_blooddis', 'diag_1_mentaldis',\n",
       "       'diag_2_infection', 'diag_1_skin', 'race_Hispanic', 'diag_3_neoplasm',\n",
       "       'age_3', 'max_glu_serum_>300', 'max_glu_serum_>200'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c456f6",
   "metadata": {},
   "source": [
    "#### Seperating out the dependent and independent variables of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a6c18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = diabetes_test.drop(columns='readmitted').values\n",
    "test_y = diabetes_test['readmitted'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd725fc0",
   "metadata": {},
   "source": [
    "### Predictions on the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4f39b",
   "metadata": {},
   "source": [
    "#### Serializing/deserializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab946f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_deployed_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "xgb_deployed_predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4759b",
   "metadata": {},
   "source": [
    "#### Creating a list of prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38bc857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15018\n"
     ]
    }
   ],
   "source": [
    "xgb_predictions = []\n",
    "xgb_results = xgb_deployed_predictor.predict(test_X)\n",
    "xgb_predictions += [r['score'] for r in xgb_results['predictions']]\n",
    "\n",
    "print(len(xgb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff0604",
   "metadata": {},
   "source": [
    "#### Adding these predictions back to the dataset as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8414b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_test['xgb_predictions'] = xgb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50bcd67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 63)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f32b781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_2_blooddis</th>\n",
       "      <th>diag_1_mentaldis</th>\n",
       "      <th>diag_2_infection</th>\n",
       "      <th>diag_1_skin</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>diag_3_neoplasm</th>\n",
       "      <th>age_3</th>\n",
       "      <th>max_glu_serum_&gt;300</th>\n",
       "      <th>max_glu_serum_&gt;200</th>\n",
       "      <th>xgb_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      readmitted  num_lab_procedures  num_medications  time_in_hospital  \\\n",
       "4294           0                  36               11                 1   \n",
       "\n",
       "      number_inpatient  num_procedures  number_diagnoses  number_outpatient  \\\n",
       "4294                 0               0                 3                  0   \n",
       "\n",
       "      number_emergency  gender_Male  ...  diag_2_blooddis  diag_1_mentaldis  \\\n",
       "4294                 0            0  ...                0                 0   \n",
       "\n",
       "      diag_2_infection  diag_1_skin  race_Hispanic  diag_3_neoplasm  age_3  \\\n",
       "4294                 0            0              0                0      1   \n",
       "\n",
       "      max_glu_serum_>300  max_glu_serum_>200  xgb_predictions  \n",
       "4294                   0                   0         0.051485  \n",
       "\n",
       "[1 rows x 63 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9bba89",
   "metadata": {},
   "source": [
    "### Predictions on the Linear Learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb0257",
   "metadata": {},
   "source": [
    "#### Serializing/deserializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "014b3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_deployed_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "linear_deployed_predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b64246",
   "metadata": {},
   "source": [
    "#### Creating a list of prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e827214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15018\n"
     ]
    }
   ],
   "source": [
    "linear_predictions = []\n",
    "linear_results = linear_deployed_predictor.predict(test_X)\n",
    "linear_predictions += [r['score'] for r in linear_results['predictions']]\n",
    "\n",
    "print(len(linear_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0662e021",
   "metadata": {},
   "source": [
    "#### Adding these predictions back to the dataset as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d198d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_test['linear_predictions'] = linear_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6d076b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54c07428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['readmitted', 'num_lab_procedures', 'num_medications',\n",
       "       'time_in_hospital', 'number_inpatient', 'num_procedures',\n",
       "       'number_diagnoses', 'number_outpatient', 'number_emergency',\n",
       "       'gender_Male', 'admission_source_id_1', 'change', 'diag_3_Nothing',\n",
       "       'age_9', 'diag_2_Nothing', 'medication_insulin', 'diag_2_respiratory',\n",
       "       'admission_type_id_3', 'diag_2_urogenital', 'age_6',\n",
       "       'medication_glyburide', 'diag_3_respiratory', 'diag_3_metabolic',\n",
       "       'medication_metformin', 'discharge_disposition_hhealth',\n",
       "       'diag_1_digestive', 'diag_1_respiratory', 'diag_1_injury', 'age_5',\n",
       "       'discharge_disposition_outpatient', 'diag_3_urogenital',\n",
       "       'discharge_disposition_nursing', 'diag_3_injury', 'diag_1_Nothing',\n",
       "       'any_medication', 'diag_1_urogenital', 'A1Cresult_Norm',\n",
       "       'diag_3_digestive', 'discharge_disposition_unknown', 'A1Cresult_>7',\n",
       "       'diag_2_skin', 'admission_source_id_8', 'diag_3_other',\n",
       "       'discharge_disposition_hospital', 'race_Other', 'diag_1_other',\n",
       "       'diag_3_skin', 'diag_1_infection', 'diag_1_musculoskeletal',\n",
       "       'diag_2_neoplasm', 'diag_1_neoplasm', 'admission_source_id_4',\n",
       "       'discharge_disposition_hospice', 'diag_2_blooddis', 'diag_1_mentaldis',\n",
       "       'diag_2_infection', 'diag_1_skin', 'race_Hispanic', 'diag_3_neoplasm',\n",
       "       'age_3', 'max_glu_serum_>300', 'max_glu_serum_>200', 'xgb_predictions',\n",
       "       'linear_predictions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f7b05",
   "metadata": {},
   "source": [
    "### Stacked Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77349f6f",
   "metadata": {},
   "source": [
    "#### Lastly, we will create a List of \"Stacked\" predictions that incorporate both of our models at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e08928",
   "metadata": {},
   "source": [
    "This is accomplished by simply scaling the prediction of each model as desired (in our case, 50-50) so that each prediction is comprised of the relationships produced by both models. This may enable relationships caputured by one model, but not the other, to be expressed within the final outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18ed5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_test[\"stacked_predictions\"] = (diabetes_test[\"xgb_predictions\"]+diabetes_test[\"linear_predictions\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "570af7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15018, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['readmitted', 'num_lab_procedures', 'num_medications',\n",
       "       'time_in_hospital', 'number_inpatient', 'num_procedures',\n",
       "       'number_diagnoses', 'number_outpatient', 'number_emergency',\n",
       "       'gender_Male', 'admission_source_id_1', 'change', 'diag_3_Nothing',\n",
       "       'age_9', 'diag_2_Nothing', 'medication_insulin', 'diag_2_respiratory',\n",
       "       'admission_type_id_3', 'diag_2_urogenital', 'age_6',\n",
       "       'medication_glyburide', 'diag_3_respiratory', 'diag_3_metabolic',\n",
       "       'medication_metformin', 'discharge_disposition_hhealth',\n",
       "       'diag_1_digestive', 'diag_1_respiratory', 'diag_1_injury', 'age_5',\n",
       "       'discharge_disposition_outpatient', 'diag_3_urogenital',\n",
       "       'discharge_disposition_nursing', 'diag_3_injury', 'diag_1_Nothing',\n",
       "       'any_medication', 'diag_1_urogenital', 'A1Cresult_Norm',\n",
       "       'diag_3_digestive', 'discharge_disposition_unknown', 'A1Cresult_>7',\n",
       "       'diag_2_skin', 'admission_source_id_8', 'diag_3_other',\n",
       "       'discharge_disposition_hospital', 'race_Other', 'diag_1_other',\n",
       "       'diag_3_skin', 'diag_1_infection', 'diag_1_musculoskeletal',\n",
       "       'diag_2_neoplasm', 'diag_1_neoplasm', 'admission_source_id_4',\n",
       "       'discharge_disposition_hospice', 'diag_2_blooddis', 'diag_1_mentaldis',\n",
       "       'diag_2_infection', 'diag_1_skin', 'race_Hispanic', 'diag_3_neoplasm',\n",
       "       'age_3', 'max_glu_serum_>300', 'max_glu_serum_>200', 'xgb_predictions',\n",
       "       'linear_predictions', 'stacked_predictions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(diabetes_test.shape)\n",
    "diabetes_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a668a",
   "metadata": {},
   "source": [
    "### 3.6 Export test data with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2252c",
   "metadata": {},
   "source": [
    "#### We will now export the finished dataset, complete with XGBoost, Linear Learner, and Stacked model predictions, for further analysis in the next script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd575d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Export_Processed_CSV(bucket, processed_data_folder, local_file_name, S3_file_name, header_presence):\n",
    "        \n",
    "    '''Exports a dataframe into CSV format, and sends to a specified S3 bucket location\n",
    "    \n",
    "    Arguments \n",
    "    --------- \n",
    "    bucket: A list of the columns (i.e. the 3 diagnosis columns) to be updated\n",
    "    processed_data_folder: the relevant subfolder within the main bucket\n",
    "    local_file_name: The name of the dataframe within the notebook\n",
    "    S3_file_name: The name of the file uppn export (with .csv extension included)\n",
    "    header_presence: whether or not a header will be present within the exported csv\n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    Exports a csv file to a specified S3 location'''\n",
    "    \n",
    "    local_file_name.to_csv(S3_file_name, index=False, header=header_presence)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object('{}/{}'.format(processed_data_folder, S3_file_name)).upload_file(S3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78f6376e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['readmitted', 'num_lab_procedures', 'num_medications',\n",
       "       'time_in_hospital', 'number_inpatient', 'num_procedures',\n",
       "       'number_diagnoses', 'number_outpatient', 'number_emergency',\n",
       "       'gender_Male', 'admission_source_id_1', 'change', 'diag_3_Nothing',\n",
       "       'age_9', 'diag_2_Nothing', 'medication_insulin', 'diag_2_respiratory',\n",
       "       'admission_type_id_3', 'diag_2_urogenital', 'age_6',\n",
       "       'medication_glyburide', 'diag_3_respiratory', 'diag_3_metabolic',\n",
       "       'medication_metformin', 'discharge_disposition_hhealth',\n",
       "       'diag_1_digestive', 'diag_1_respiratory', 'diag_1_injury', 'age_5',\n",
       "       'discharge_disposition_outpatient', 'diag_3_urogenital',\n",
       "       'discharge_disposition_nursing', 'diag_3_injury', 'diag_1_Nothing',\n",
       "       'any_medication', 'diag_1_urogenital', 'A1Cresult_Norm',\n",
       "       'diag_3_digestive', 'discharge_disposition_unknown', 'A1Cresult_>7',\n",
       "       'diag_2_skin', 'admission_source_id_8', 'diag_3_other',\n",
       "       'discharge_disposition_hospital', 'race_Other', 'diag_1_other',\n",
       "       'diag_3_skin', 'diag_1_infection', 'diag_1_musculoskeletal',\n",
       "       'diag_2_neoplasm', 'diag_1_neoplasm', 'admission_source_id_4',\n",
       "       'discharge_disposition_hospice', 'diag_2_blooddis', 'diag_1_mentaldis',\n",
       "       'diag_2_infection', 'diag_1_skin', 'race_Hispanic', 'diag_3_neoplasm',\n",
       "       'age_3', 'max_glu_serum_>300', 'max_glu_serum_>200', 'xgb_predictions',\n",
       "       'linear_predictions', 'stacked_predictions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62d99e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_predictions = \"test_with_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5237deff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "Export_Processed_CSV(bucket, input_prefix, diabetes_test, test_with_predictions, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50a2bd",
   "metadata": {},
   "source": [
    "Please continue to the fourth script in this repository: 4. Evaluation_on_Test_Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
